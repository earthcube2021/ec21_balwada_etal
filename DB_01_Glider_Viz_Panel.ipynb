{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glider Viz Panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "**Dhruv Balwada, Scott Henderson, Alison R Gray**\n",
    "- Author1 = {\"name\": \"Dhruv Balwada\", \"affiliation\": \"School of Oceanography, University of Washington\", \"email\": \"dbalwada@uw.edu\", \"orcid\": \"0000-0001-6632-0187\"}\n",
    "- Author2 = {\"name\": \"Scott Henderson\", \"affiliation\": \"Earth and Space Sciences, University of Washington\", \"email\": \"scottyh@uw.edu\", \"orcid\": \"0000-0003-0624-4965\"}\n",
    "- Author3 = {\"name\": \"Alison R Gray\", \"affiliation\": \"School of Oceanography, University of Washington\", \"email\": \"argray@uw.edu\", \"orcid\": \"0000-0002-1644-7654\"}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "Many oceanographic observational platforms, such as gliders, Argo floats, or ships, collect measurements on complex spatio-temporal paths. These sampling patterns are sometimes determined by logistical choices, e.g. due to weather, or sometimes dictated by the underlying oceanic flow causing the platforms to drift around. Deriving insights from these observations is challenging, and researchers almost always need to manually inspect the data. One such manual task might be to distinguish between signals that result due to sampling patterns vs signals that are an actual representation of the environment being studied.\n",
    "For example, a feature drifting by a  stationary platform, which samples the same location repeatedly, might look similar to a slowly evolving feature that a platform traverses through. These distinctions can be made by carefully inspecting the path of the instrument in reference to background measurements, like those from satellites, and this task can be made easier by using interactive visualizations. \n",
    "\n",
    "This notebook presents a workflow for setting up a visualization dashboard to interact with and analyze ocean glider data in combination with other available background measurements (eg. sea surface height, climatology, etc) that might be available in the geographical region sampled by the glider. This interactive visualization dashboard allows for easier data exploration and accelerates the rate at which insights can be derived. The primary purpose of this notebook is  not to simply build a standalone visualization dashboard for our specific data set, but rather provide an example that can be easily adapted to the specific use cases that individual researchers might have.\n",
    "\n",
    "We visualize data for a particular glider campaign that was conducted in the Southern Ocean from May to August 2019, where two SeaGliders sampled the top 1000m of the ocean water column (a profile every 4 hours) in close proximity to each other. Sea Surface Height (SSH) and Finite Size Lypunov Exponents (FSLE, a measure of strain in the flow) are available from satellite based measurements and help provide background context in the sampling region. \n",
    "\n",
    "## Technical contributions\n",
    "The main technical contributions of this notebook are as follows:\n",
    "- demonstrates how [GliderTools](https://glidertools.readthedocs.io/en/latest/) in combination with Scipy interpolation routines can be used to grid data collected by gliders, which is stored as point measurements.\n",
    "- demonstrates how [Xarray](http://xarray.pydata.org/) and the [Holoviz](https://holoviz.org/) visualization ecosystem, such as panel, hvplot, geoviews etc, can be used in combination to easily setup an interactive visualization tool to analyze glider data. \n",
    "\n",
    "## Methodology\n",
    "The glider data is a collection of point measurements in space and time, where each measured variable has an associated position (longitude, latitude, depth) and time stamp. The glider data can be loaded and quality controlled using [GliderTools](https://glidertools.readthedocs.io/en/latest/). For making visualization easy and more interpretable this data is first gridded onto two regular grids; one is a time vs depth grid (T-grid) and the other other is an along track distance vs depth grid (D-grid). The T-grid helps visualize the duration of time over which different signals are observed, while the D-grid helps visualize the spatial size of the objects in the platform following coordinate. The gridding also helps colocate variables that might be slightly offset due to the different sampling frequencies of different sensors.  This gridded data set is then visualized along with the SSH and FSLE data sets, which are already available on a uniform grid.\n",
    "\n",
    "The visualization dashboard has three main parts. The first part is a set of widgets that allow the user to make choices, such as selecting which variable to plot, the range of time or distance, choice of colormaps etc. The second part is a spatial plot of the surface properties (SSH or FSLE) with the glider tracks overlaid on it, where the selected glider and time slice to plot are based on the widgets. The third part is a plot of the glider section, where the exact range of time or distances plotted and the variables plotted are based on the variables. \n",
    "\n",
    "The visualization is made possible using the [Holoviz](https://holoviz.org/) libraries. Each widget selection sets the value of a certain parameter using the [param](https://param.holoviz.org/index.html) library, where parameters could be the variable to plot, the choice of colormap, etc. The plots are made possible using the libraries like [HoloViews](https://holoviews.org/), [hvPlot](https://hvplot.holoviz.org/), or [GeoViews](http://geoviews.org/). The parameter values are relayed to the plots using [Panel](https://panel.holoviz.org/), which also controls of the layout of the different components and manages the updates when interactions take place.\n",
    "\n",
    "\n",
    "## Results\n",
    "The main purpose of this notebook is to demonstrate how a dashboard to explore glider data can be built using open source packages. The code is demonstrated in detail below and will hopefully serve as a useful example for others to explore their own datasets. The final cell of the notebook should result in dashboard that can be displayed in a notebook cell or in a standalone browser window. Some of the features of this dashboard are showcased in the gif below. The dashboard can also be accessed directly, without running all the cells in this notebook, by using the link to the 'Binder panel' in the repo readme; this makes the dashboard particularly appealing for sharing with collaborators that do not want to run the code.\n",
    "\n",
    "![Animation showing how to use some of the different features of the glider dashboard.](glider_dashboard.gif)\n",
    "\n",
    "## Funding\n",
    "\n",
    "- Award1 = {\"agency\": \"US National Science Foundation\", \"award_code\": \"OCE-1756882\", \"award_URL\": \"https://www.nsf.gov/awardsearch/showAward?AWD_ID=1756882\"}\n",
    "\n",
    "## Keywords\n",
    "\n",
    "keywords=[\"gliders\", \"interactive visualization\", \"ocean tracers\", \"submesoscale variability\"]\n",
    "\n",
    "## Citation\n",
    "Balwada, Henderson, & Gray 2021. Interactive visualization tools for ocean glider data. Accessed at https://github.com/dhruvbalwada/ec2021_balwada_etal\n",
    "\n",
    "\n",
    "## Suggested next steps\n",
    "\n",
    "- We recommend that readers try to adapt this dashboard for their own datasets! \n",
    "- To generalize the current dashboard code to use with additional datasets, it would be useful to add an option to read remote web-optimized formats instead of storing preprocessed netcdf datasets with the dashboard code. \n",
    "- A few possible (non-essential) user experience improvements were identified (see wishlist on https://github.com/dhruvbalwada/glider-panel-demo), which can incorporated in future releases.\n",
    "\n",
    "## Acknowledgements \n",
    "This project was supported by University of Washington's [eScience Institute](https://escience.washington.edu/) as part of the the 2021 [Winter Incubator](https://escience.washington.edu/winter-2021-incubator-projects/), and benefited from conversations with [Rob Fatland](https://escience.washington.edu/people/rob-fatland/) and [Don Setiawan](https://escience.washington.edu/people/landung-don-setiawan/) during the incubator. \n",
    "We would also like to thank [Lily Dove](https://www.gps.caltech.edu/people/lilian-a-lily-dove?back_url=%2Fpeople%3Fcategory%3D11) and [Andrew Thompson](http://web.gps.caltech.edu/~andrewt/) from Caltech who processed a lot of the glider data that is used here, and a version of this data in a kriging mapped format can be found at https://www.ncei.noaa.gov/archive/accession/0228185 and https://www.ncei.noaa.gov/archive/accession/0228187. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Library import\n",
    "Import all the required Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data manipulation\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import glidertools as gt\n",
    "import os\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# For Visualization\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "import geoviews as gv\n",
    "import param\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Import hvplot apis for xarray and pandas\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import\n",
    "\n",
    "## Import glider data\n",
    "\n",
    "Two gliders were deployed in the Southern Ocean from May-August 2019 as part of an experiment called SOGOS (Southern Ocean Glider Observations of the Submesoscales). Here we use the data from these gliders, which is provided in the `data` folder. This data is stored in single netcdf files for each sensor, where each file contains the data for all the glider dives. This data can be opened directly using xarray.\n",
    "\n",
    "Alternatively, often glider data is provided in single netcdf file for each dive. This dive data could be loaded using the instructions at https://glidertools.readthedocs.io/en/latest/loading.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate the data folder\n",
    "data_folder = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open glider files\n",
    "\n",
    "ds_CTD_659 = xr.load_dataset(os.path.join(data_folder , 'sg659', 'CTD_659.nc'))\n",
    "ds_CTD_660 = xr.load_dataset(os.path.join(data_folder , 'sg660', 'CTD_660.nc'))\n",
    "\n",
    "ds_O2_659 = xr.load_dataset(os.path.join(data_folder , 'sg659', 'O2_659.nc'))\n",
    "ds_O2_660 = xr.load_dataset(os.path.join(data_folder , 'sg660', 'O2_660.nc'))\n",
    "\n",
    "ds_Chl_659 = xr.load_dataset(os.path.join(data_folder , 'sg659', 'Chl_659.nc'))\n",
    "ds_Chl_660 = xr.load_dataset(os.path.join(data_folder , 'sg660', 'Chl_660.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data files are stored as 1D arrays of measurements at each observation point, where the location (longitude, latitude, and depth) and time of measurement for the observation point are also part of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print to see what the data format is\n",
    "ds_CTD_659"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import surface data \n",
    "\n",
    "The sea surface height (SSH) and finite scale Lyapunov exponent (FSLE) datasets were obtained from the Copernicus and Aviso websites respectively, and manually cut for the region and time period of the glider deployments. Other data sets can also be similarly accessed; some community datasets could also be directly accessed using different webservices.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open SSH and FSLE files\n",
    "ds_ssh = xr.open_dataset(os.path.join(data_folder, 'SSH_sogos.nc'))\n",
    "ds_fsle = xr.open_dataset(os.path.join(data_folder, 'FSLE_sogos.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print to see what the data format is\n",
    "ds_ssh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing and analysis\n",
    "\n",
    "We first show how the data sets are processed to a form that is easily digestable by the visualization libraries. Then we show how the visualization libraries can be used to easily setup an interactive dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime2ytd(time):\n",
    "    \"\"\"\" Return time in YTD format from datetime format.\"\"\"\n",
    "    return  (time - np.datetime64('2019-01-01'))/np.timedelta64(1, 'D')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables for quiver plot\n",
    "# Quiver plot requires the vectors to be defined in a very specific format.\n",
    "ds_ssh['mag'] = np.sqrt(ds_ssh.ugos**2 + ds_ssh.vgos**2)\n",
    "ds_ssh['angle'] = (np.pi/2.) - np.arctan2(ds_ssh.ugos/ds_ssh['mag'], \n",
    "                                          ds_ssh.vgos/ds_ssh['mag'])\n",
    "\n",
    "# Create a new coordinate with time in year day units, as it is easier to work with.\n",
    "# In future version handling of regular datetime formats could be introduced.\n",
    "ds_ssh = ds_ssh.assign_coords(days = datetime2ytd(ds_ssh.time))\n",
    "ds_fsle = ds_fsle.assign_coords(days = datetime2ytd(ds_fsle.time))\n",
    "\n",
    "del ds_ssh.attrs['_NCProperties']\n",
    "# need to delete this attribute because of the issue:\n",
    "# https://github.com/pydata/xarray/issues/2822"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glider Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert glider time axis also to year day units, \n",
    "# so it matches that units for surface properties.\n",
    "\n",
    "ds_CTD_659['days'] = datetime2ytd(ds_CTD_659.time)\n",
    "ds_O2_659['days']  = datetime2ytd(ds_O2_659.time)\n",
    "ds_Chl_659['days'] = datetime2ytd(ds_Chl_659.time)\n",
    "\n",
    "ds_CTD_660['days'] = datetime2ytd(ds_CTD_660.time)\n",
    "ds_O2_660['days']  = datetime2ytd(ds_O2_660.time)\n",
    "ds_Chl_660['days'] = datetime2ytd(ds_Chl_660.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate along track distance\n",
    "dXdist = gt.utils.distance(ds_CTD_659.longitude, ds_CTD_659.latitude)/1e3 # Convert to km\n",
    "ds_CTD_659['distance'] = xr.DataArray(np.nancumsum(dXdist), \n",
    "                                       dims=ds_CTD_659.dims,\n",
    "                                       coords=ds_CTD_659.coords)\n",
    "\n",
    "dXdist = gt.utils.distance(ds_CTD_660.longitude, ds_CTD_660.latitude)/1e3\n",
    "ds_CTD_660['distance'] = xr.DataArray(np.nancumsum(dXdist), \n",
    "                                       dims=ds_CTD_660.dims,\n",
    "                                       coords=ds_CTD_660.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and average locations by dives \n",
    "# This makes plotting of locations on a map much faster, as\n",
    "# there are less points to plot.\n",
    "# These are used is only for plotting on a 2D map,\n",
    "# where the depth coordinate is compressed.\n",
    "ds_659_locs = xr.Dataset()\n",
    "ds_660_locs = xr.Dataset()\n",
    "\n",
    "ds_659_diveav = ds_CTD_659.groupby('dives').mean()\n",
    "ds_660_diveav = ds_CTD_660.groupby('dives').mean()\n",
    "\n",
    "ds_659_locs['longitude'] = ds_659_diveav.longitude\n",
    "ds_659_locs['latitude']  = ds_659_diveav.latitude\n",
    "ds_659_locs['days']      = ds_659_diveav.days\n",
    "ds_659_locs['distance']  = ds_659_diveav.distance\n",
    "\n",
    "ds_660_locs['longitude'] = ds_660_diveav.longitude\n",
    "ds_660_locs['latitude']  = ds_660_diveav.latitude\n",
    "ds_660_locs['days']      = ds_660_diveav.days\n",
    "ds_660_locs['distance']  = ds_660_diveav.distance\n",
    "\n",
    "# convert to pandas dataframe as it is much easier to handle in holoviz for traj data.\n",
    "ds_659_locs = ds_659_locs.to_dataframe()\n",
    "ds_660_locs = ds_660_locs.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate additional derived variables\n",
    "# Here we estimate density from the CTD measurements \n",
    "ds_CTD_659['potdens'] = gt.physics.potential_density(ds_CTD_659.salinity, \n",
    "                                                     ds_CTD_659.temperature, \n",
    "                                                     ds_CTD_659.pressure, \n",
    "                                                     ds_CTD_659.latitude, \n",
    "                                                     ds_CTD_659.longitude)\n",
    "\n",
    "ds_CTD_660['potdens'] = gt.physics.potential_density(ds_CTD_660.salinity, \n",
    "                                                     ds_CTD_660.temperature, \n",
    "                                                     ds_CTD_660.pressure,\n",
    "                                                     ds_CTD_660.latitude, \n",
    "                                                     ds_CTD_660.longitude)\n",
    "\n",
    "# we can add mixed layer depth, N2 etc in the future versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have calculated some extra variables and new coordinates, we will go to the step of gridding the data onto a regular grid. \n",
    "\n",
    "In addition to the above tasks additional quality control procedures can be introduced at this stage (prior to gridding), using the QC procedures that are part of GliderTools (https://glidertools.readthedocs.io/en/latest/quality_control.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make functions that put the point measurements from the glider \n",
    "# onto a regular grid. \n",
    "# There are many ways this can be done. Here we choose a simple linear interpolation \n",
    "# in time and pressure/depth or along-track distance and pressure/depth.\n",
    "\n",
    "# Note this is different from how Glidertools goes gridding at the moment.\n",
    "# These functions might be absorbed into Glidertools in future releases.\n",
    "\n",
    "def interp_pres_time(ds_glid, var): \n",
    "    \"\"\" Return data variable interpolated onto a pressure-time grid.\n",
    "    \n",
    "    Keyword argument.\n",
    "    ds_glid -- dataset of the glider data\n",
    "    var     -- variable that needs to be interpolated\n",
    "    \"\"\"\n",
    "    pres_ug = ds_glid.pressure\n",
    "    time_ug = ds_glid.days\n",
    "    \n",
    "    # convert to points values\n",
    "    points = np.stack([time_ug.values, pres_ug.values], axis=1)\n",
    "    values = ds_glid[var].values\n",
    "    \n",
    "    # remove nans\n",
    "    non_nan = np.logical_and(np.logical_and(\n",
    "                                    ~np.isnan(points[:,0]), \n",
    "                                    ~np.isnan(points[:,1])),\n",
    "                              ~np.isnan(values))\n",
    "    \n",
    "    points =points[non_nan,:]\n",
    "    values =values[non_nan]\n",
    "    \n",
    "    # define grid \n",
    "    # In the future this can be made into an input from the users\n",
    "    pres_grid = np.linspace(0,1000,251) \n",
    "    time_grid = np.arange(119, 207, 2/24)\n",
    "    grid_p, grid_t = np.meshgrid(pres_grid, time_grid)\n",
    "    \n",
    "    temp_grided = griddata(points, \n",
    "                           values, \n",
    "                           (grid_t, grid_p), \n",
    "                           method='linear', \n",
    "                           rescale=True)\n",
    "    \n",
    "    return xr.DataArray(temp_grided.T, \n",
    "                        dims=[\"pressure\", \"time\"],\n",
    "                        coords={\"pressure\":pres_grid, \"time\":time_grid}\n",
    "                       ).rename(var)\n",
    "\n",
    "\n",
    "def interp_pres_dist(ds_glid, var): \n",
    "    \"\"\" Return data variable interpolated onto a pressure-along track distance grid.\n",
    "    \n",
    "    Keyword argument.\n",
    "    ds_glid -- dataset of the glider data\n",
    "    var     -- variable that needs to be interpolated\n",
    "    \"\"\"\n",
    "    pres_ug = ds_glid.pressure\n",
    "    dist_ug = ds_glid.distance\n",
    "    \n",
    "    # convert to points values\n",
    "    points = np.stack([dist_ug.values, pres_ug.values],axis=1)\n",
    "    values = ds_glid[var].values\n",
    "    \n",
    "    # remove nans\n",
    "    non_nan = np.logical_and(np.logical_and(\n",
    "                                    ~np.isnan(points[:,0]), \n",
    "                                    ~np.isnan(points[:,1])),\n",
    "                             ~np.isnan(values))\n",
    "    \n",
    "    points =points[non_nan,:]\n",
    "    values =values[non_nan]\n",
    "    \n",
    "    # define grid\n",
    "    # In the future this can be made into an input from the users    \n",
    "    pres_grid = np.linspace(0,1000,251)\n",
    "    dist_grid = np.arange(0, dist_ug.max().values, 3)\n",
    "    grid_p, grid_d = np.meshgrid(pres_grid, dist_grid)\n",
    "    \n",
    "    temp_grided = griddata(points, \n",
    "                           values, \n",
    "                           (grid_d, grid_p), \n",
    "                           method='linear', \n",
    "                           rescale=True)\n",
    "    \n",
    "    return xr.DataArray(temp_grided.T, \n",
    "                        dims=[\"pressure\", \"distance\"],\n",
    "                        coords={\"pressure\":pres_grid, \"distance\":dist_grid}\n",
    "                       ).rename(var)\n",
    "\n",
    "\n",
    "def convert_glider_time_pres(ds_glid, vars_convert= ['temperature','salinity','potdens','spice']):\n",
    "    \"\"\" Return a dataset gridded onto pressure vs time grid.\n",
    "    \n",
    "    This is a helper function to apply gridding to multiple glider variables.\n",
    "    \"\"\"    \n",
    "    ds_grid = xr.Dataset()\n",
    "    \n",
    "    for v in vars_convert:\n",
    "        ds_grid[v] = interp_pres_time(ds_glid, v)\n",
    "        print('Gridded ' + v)\n",
    "        \n",
    "    return ds_grid\n",
    "\n",
    "def convert_glider_dist_pres(ds_glid, vars_convert= ['temperature','salinity','potdens','spice']):\n",
    "    \"\"\" Return a dataset gridded onto pressure vs along track distance grid.\n",
    "    \n",
    "    This is a helper function to apply gridding to multiple glider variables.\n",
    "    \"\"\" \n",
    "    ds_grid = xr.Dataset()\n",
    "    \n",
    "    for v in vars_convert:\n",
    "        ds_grid[v] = interp_pres_dist(ds_glid, v)\n",
    "        print('Gridded ' + v)\n",
    "    \n",
    "    return ds_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some variables measured by different sensors might be at different points. \n",
    "# Here we use a simple interpolation, from numpy, to collocate the Oxygen and Chlorophyll\n",
    "# measurements to the CTD data point.\n",
    "\n",
    "ds_CTD_659['oxygen'] = xr.DataArray(np.interp(ds_CTD_659.days, ds_O2_659.days, ds_O2_659.oxygen),\n",
    "                                    dims = ds_CTD_659.dims, \n",
    "                                    coords = ds_CTD_659.coords\n",
    "                                   ).rename('oxygen')\n",
    "ds_CTD_659['Chl'] = xr.DataArray(np.interp(ds_CTD_659.days, ds_Chl_659.days, ds_Chl_659.Chl),\n",
    "                                 dims = ds_CTD_659.dims, \n",
    "                                 coords = ds_CTD_659.coords\n",
    "                                ).rename('Chl')\n",
    "ds_CTD_660['oxygen'] = xr.DataArray(np.interp(ds_CTD_660.days, ds_O2_660.days, ds_O2_660.oxygen),\n",
    "                                    dims = ds_CTD_660.dims, \n",
    "                                    coords = ds_CTD_660.coords\n",
    "                                   ).rename('oxygen')\n",
    "ds_CTD_660['Chl'] = xr.DataArray(np.interp(ds_CTD_660.days, ds_Chl_660.days, ds_Chl_660.Chl),\n",
    "                                 dims = ds_CTD_660.dims, \n",
    "                                 coords = ds_CTD_660.coords\n",
    "                                ).rename('Chl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The next 4 cells can take a lot of time to run as a lot of compute heavy interpolations need to be done. \n",
    "At this point the `load_flag` is set to 1, which will bypass the code in these cells without doing anything. The data that is generated here has been saved and provided with the repo, which will be loaded in the 5th cell below. \n",
    "However, incase you want to run these set the `load_flag` to 0. \n",
    "These cells will run with some waiting on local machines; while I have managed to get these to run on Binder, it often crashes due to the 2gb limit on Binder memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# convert from point data to gridded data\n",
    "# This cell will take the most time to run \n",
    "# (~10mins on laptop, ~20 mins on Binder). \n",
    "\n",
    "load_flag = 1 # Set this to 1 for loading the data instead of running the cells below, or 0 if you want to see what these cells do\n",
    "if load_flag == 0:\n",
    "    ds_659_Tgrid = convert_glider_time_pres(ds_CTD_659, vars_convert= ['temperature','salinity','potdens', 'oxygen', 'Chl'])\n",
    "    ds_660_Tgrid = convert_glider_time_pres(ds_CTD_660, vars_convert= ['temperature','salinity','potdens', 'oxygen', 'Chl'])\n",
    "\n",
    "    ds_659_Dgrid = convert_glider_dist_pres(ds_CTD_659, vars_convert= ['temperature','salinity','potdens', 'oxygen', 'Chl'])\n",
    "    ds_660_Dgrid = convert_glider_dist_pres(ds_CTD_660, vars_convert= ['temperature','salinity','potdens', 'oxygen', 'Chl'])\n",
    "\n",
    "\n",
    "# Alternatively users can separate the data processing and data \n",
    "# visualization sections into separate notebooks, and the gridded output can be generated once \n",
    "# and saved as netcdf files (using xarray's .to_netcdf() option). These netcdf files can then \n",
    "# directly be read into a visualization only notebook. \n",
    "# An example of how to do this is available at: https://github.com/dhruvbalwada/glider-panel-demo\n",
    "# This is how the data sets were saved, which are being loaded if load_flag is set to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate an anomaly field based on time mean. \n",
    "# This is just an additional variable that we were interested in looking at.\n",
    "# Could be defined in more complex ways too, like choose climatology as mean.\n",
    "if load_flag == 0:\n",
    "    ds_659_Tgrid_anomaly = ds_659_Tgrid - ds_659_Tgrid.mean('time')\n",
    "    ds_660_Tgrid_anomaly = ds_660_Tgrid - ds_660_Tgrid.mean('time')\n",
    "\n",
    "    ds_659_Dgrid_anomaly = ds_659_Dgrid - ds_659_Dgrid.mean('distance')\n",
    "    ds_660_Dgrid_anomaly = ds_660_Dgrid - ds_660_Dgrid.mean('distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the distance axis that goes with the time axis\n",
    "# The gridding to a time axis was done for a uniform time grid,\n",
    "# so the associated distance axis will likely be non-uniform.\n",
    "if load_flag == 0:\n",
    "    ds_659_Tgrid_loc = convert_glider_time_pres(ds_CTD_659, vars_convert= ['latitude','longitude'])\n",
    "    ds_660_Tgrid_loc = convert_glider_time_pres(ds_CTD_660, vars_convert= ['latitude','longitude'])\n",
    "\n",
    "    dXdist = gt.utils.distance(ds_659_Tgrid_loc.longitude.mean('pressure'), \n",
    "                               ds_659_Tgrid_loc.latitude.mean('pressure'))/1e3\n",
    "    ds_659_Tgrid['distance'] = np.nancumsum(dXdist)\n",
    "    ds_659_Tgrid_anomaly['distance'] = np.nancumsum(dXdist)\n",
    "\n",
    "    dXdist = gt.utils.distance(ds_660_Tgrid_loc.longitude.mean('pressure'), \n",
    "                               ds_660_Tgrid_loc.latitude.mean('pressure'))/1e3\n",
    "\n",
    "    ds_660_Tgrid['distance'] = np.nancumsum(dXdist)\n",
    "    ds_660_Tgrid_anomaly['distance'] = np.nancumsum(dXdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the time axis that goes with the along track distance \n",
    "# Similar to above cell, but now the non-uniform time axis that goes \n",
    "# with the uniform distance axis. \n",
    "if load_flag == 0:\n",
    "    temp = convert_glider_dist_pres(ds_CTD_659, vars_convert=['days'])\n",
    "    ds_659_Dgrid['time'] = temp.days.mean('pressure').values\n",
    "\n",
    "    temp = convert_glider_dist_pres(ds_CTD_660, vars_convert=['days'])\n",
    "    ds_660_Dgrid['time'] = temp.days.mean('pressure').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incase you don't have the time to run the above 4 cells\n",
    "# Or if binder keeps crashing trying to run the above 4 cells.\n",
    "\n",
    "if load_flag == 1:\n",
    "    ds_659_Tgrid = xr.open_dataset(os.path.join(data_folder, '659_Tgrid.nc'))\n",
    "    ds_660_Tgrid = xr.open_dataset(os.path.join(data_folder, '660_Tgrid.nc'))\n",
    "\n",
    "    ds_659_Tgrid_anomaly = xr.open_dataset(os.path.join(data_folder, '659_Tgrid_anomaly.nc'))\n",
    "    ds_660_Tgrid_anomaly = xr.open_dataset(os.path.join(data_folder, '660_Tgrid_anomaly.nc'))\n",
    "\n",
    "    ds_659_Dgrid = xr.open_dataset(os.path.join(data_folder, '659_Dgrid.nc'))\n",
    "    ds_660_Dgrid = xr.open_dataset(os.path.join(data_folder, '660_Dgrid.nc'))\n",
    "\n",
    "    ds_659_Dgrid_anomaly = xr.open_dataset(os.path.join(data_folder, '659_Dgrid_anomaly.nc'))\n",
    "    ds_660_Dgrid_anomaly = xr.open_dataset(os.path.join(data_folder, '660_Dgrid_anomaly.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point in the notebook all the data processing steps have been executed, and the data sets are in a format that is ready to be visualized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the interactive dashboard\n",
    "\n",
    "This is the main contribution of this submission. Here we show how Holoviz libraries can be used to create an interactive visualization of glider data. The visualization choices here are based on our particular use case, and we accordingly chose the variables that will be plotted and the widgets that are available. However, this notebook should be viewed more as an example that can be modified to the particular visualization use case that others might have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable maps \n",
    "# These are dictionaries linking variable names to particular data sets\n",
    "\n",
    "# The different gliders\n",
    "glider_nums = ['sg659', 'sg660']\n",
    "\n",
    "# The different surface variables\n",
    "surface_var_map = {\n",
    "              'SSH' : ds_ssh['adt'],\n",
    "              'SSHA': ds_ssh['sla'],\n",
    "              'FSLE': ds_fsle['fsle_max']\n",
    "              }\n",
    "\n",
    "# The different variables in a particular glider data set\n",
    "glider_vars = list(ds_659_Tgrid.keys()) # just need to do once bevause all glider data sets here have same variables\n",
    "\n",
    "# The different colormaps available\n",
    "cmap_options = plt.colormaps()\n",
    "\n",
    "# Dictionary linking variables to default properties\n",
    "# Here we only define a default colormap, but other defaults \n",
    "# can be added.\n",
    "var_select_map = {\n",
    "            'oxygen': {'cmap_sel': 'YlOrBr' },\n",
    "            'Chl': {'cmap_sel': 'Greens' },\n",
    "            'salinity': {'cmap_sel': 'YlGnBu'},\n",
    "            'temperature': {'cmap_sel': 'RdBu_r'},\n",
    "            'potdens': {'cmap_sel': 'Purples' }\n",
    "             }\n",
    "# For future versions would be nice if some of these things could come from the attributes. \n",
    "\n",
    "# Different data sets for each glider\n",
    "glider_map = {\n",
    "            'sg659': {'Time grid': ds_659_Tgrid, 'Distance grid': ds_659_Dgrid, 'loc': ds_659_locs},\n",
    "            'sg660': {'Time grid': ds_660_Tgrid, 'Distance grid': ds_660_Dgrid, 'loc': ds_660_locs},\n",
    "             }\n",
    "\n",
    "glider_map_anom = {\n",
    "            'sg659': {'Time grid': ds_659_Tgrid_anomaly, 'Distance grid': ds_659_Dgrid_anomaly},\n",
    "            'sg660': {'Time grid': ds_660_Tgrid_anomaly, 'Distance grid': ds_660_Dgrid_anomaly},\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dashboard will be made using three classes that will correspond to the:\n",
    "- Widgets: `GliderParams`: containing definitions of all the widgets.\n",
    "- Trajectory plot: `GliderTrajectoryPlot`: sets up the plot with the glider trajectories overlaid on the surface variable plots and bahtymetry.\n",
    "- Glider section plot: `GliderVerticalSectionPlot`: sets up the plot for the glider section.\n",
    "\n",
    "The plotting classes will inherit the class with the widgets, and then a combined class (`GliderCombinedPlot`) will inherit the plotting classes. The dashboard will be an object of this combined class, which can be passed to panel for being layed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GliderParams(param.Parameterized):\n",
    "    \"\"\" Class containting all the parameters for the widgets, and some default methods. \"\"\"\n",
    "    \n",
    "    surface_var       = param.Selector(surface_var_map.keys(), default='SSH',\n",
    "                                       label='Surface Field', precedence=0)\n",
    "    glider_num        = param.Selector(glider_map.keys(), default='sg659',\n",
    "                                       label='Glider Num', precedence=0)\n",
    "    time_slider       = param.Range(label='Days in 2019', \n",
    "                                    bounds=(119, 205), \n",
    "                                    default=(119, 135), precedence=3)\n",
    "    alpha_slider      = param.Magnitude(label='Transparency', precedence=4)\n",
    "    glider_grid       = param.Selector(['Time grid', 'Distance grid'], default='Time grid', \n",
    "                                       label='Grid Type', precedence=0)\n",
    "    glider_var        = param.Selector(glider_vars, default='temperature', \n",
    "                                       label='Glider Variable', precedence=1)\n",
    "    var_colormap      = param.Selector(default='RdBu_r', objects=cmap_options, \n",
    "                                       label='Glider Section Colormap', precedence=2)\n",
    "    distance_slider   = param.Range(label='Along Track Distance',\n",
    "                                    bounds=(0, 2.2e3), default=(0, 400), \n",
    "                                    precedence=-1) # start with a negative precedence, in accordance with default being Tgrid\n",
    "    anomaly_boolean   = param.Boolean(default=False, label='Anomaly', precedence=3)\n",
    "    density_boolean   = param.Boolean(default=True, label='Show Density Contours', precedence=4)\n",
    "    density_range     = param.Range(label='Density range', bounds=(1026.8, 1027.9), default=(1026.8, 1027.9),precedence=10)\n",
    "    density_gradation = param.Integer(label='Density levels', default=11, bounds=(2, 21),precedence=10)\n",
    "    \n",
    "    def _set_tools(self, plot, element):\n",
    "        \"\"\" Method to not revome default active toolbars. \"\"\"\n",
    "        plot.state.toolbar.active_drag = None\n",
    "        plot.state.toolbar.active_inspect = None\n",
    "    \n",
    "    @param.depends('glider_var', watch=True)\n",
    "    def _update_colormap(self):\n",
    "        \"\"\" Update default colormap choices with changing variables. \"\"\"\n",
    "        self.var_colormap = var_select_map[self.glider_var]['cmap_sel']\n",
    "    \n",
    "    # The next couple of methods toggle the widgets visible or not. \n",
    "    @param.depends('density_boolean', watch=True)\n",
    "    def _update_density_widgets(self):\n",
    "        \"\"\" Remove density widgets when not being used. \"\"\" \n",
    "        if self.density_boolean:\n",
    "            self.param.density_range.precedence=10\n",
    "            self.param.density_gradation.precedence=10\n",
    "        else:\n",
    "            self.param.density_range.precedence=-1\n",
    "            self.param.density_gradation.precedence=-1\n",
    "            \n",
    "    @param.depends('glider_grid', watch=True)\n",
    "    def _update_grid_widgets(self):\n",
    "        \"\"\" Show time or distance widgets based on grid choice. \"\"\"\n",
    "        if self.glider_grid == 'Time grid':\n",
    "            self.param.time_slider.precedence=3\n",
    "            self.param.distance_slider.precedence=-1\n",
    "        else: \n",
    "            self.param.time_slider.precedence=-1\n",
    "            self.param.distance_slider.precedence=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GliderTrajectoryPlot(GliderParams):\n",
    "    \"\"\" Class containing the setup for the trajectory plot. \"\"\"\n",
    "    \n",
    "    @param.depends('glider_num', 'time_slider', 'distance_slider')\n",
    "    def plot_traj(self):\n",
    "        \"\"\" Plot glider trajectories. \"\"\"\n",
    "        time_rng = self.time_slider\n",
    "        dist_rng = self.distance_slider\n",
    "        \n",
    "        ###\n",
    "        # For the selected glider do the proper time vs distance conversion\n",
    "        # but for the unselected glider and surface plots always stick to the\n",
    "        # corresponding time \n",
    "        ds = glider_map[self.glider_num]['loc']\n",
    "        if self.glider_grid=='Time grid':\n",
    "            ds_tsel = ds.loc[(ds.days>=time_rng[0]) & (ds.days<=time_rng[1])]\n",
    "            dsel = (ds_tsel.iloc[0].distance, ds_tsel.iloc[-1].distance)\n",
    "            self.distance_slider = dsel\n",
    "        else:\n",
    "            ds_tsel = ds.loc[(ds.distance>=dist_rng[0]) & (ds.distance<=dist_rng[1])]\n",
    "            if int(ds_tsel.iloc[-1].days)<=205: # since the netcdf files for surface fields don't have a 206\n",
    "                tsel = (int(ds_tsel.iloc[0].days), int(ds_tsel.iloc[-1].days))\n",
    "            else:\n",
    "                tsel = (int(ds_tsel.iloc[0].days), int(205))\n",
    "            self.time_slider = tsel\n",
    "        ###\n",
    "        \n",
    "        time_rng = self.time_slider # make sure time_rng has the most up to date values\n",
    "        \n",
    "        traj = {}\n",
    "        for glid in glider_nums:\n",
    "            ds = glider_map[glid]['loc']\n",
    "            ds_tsel = ds.loc[(ds.days>time_rng[0]) & (ds.days<time_rng[1])]\n",
    "        \n",
    "            traj[glid] = ds_tsel.hvplot.points(geo=True,  x='longitude', y='latitude', \n",
    "                                               hover=True, hover_cols=['days'], \n",
    "                                               size=1)\n",
    "        traj[self.glider_num].opts(size=2.5)\n",
    "        \n",
    "        return traj['sg659']*traj['sg660']\n",
    "    \n",
    "    def surf_tiles(self):\n",
    "        \"\"\" Plot bathymetry tile. \"\"\"\n",
    "        gebco_tiles = 'https://tiles.arcgis.com/tiles/C8EMgrsFcRFL6LrL/arcgis/rest/services/GEBCO_basemap_NCEI/MapServer/tile/{Z}/{Y}/{X}'\n",
    "        return gv.WMTS( gebco_tiles )\n",
    "    \n",
    "    @param.depends('time_slider')\n",
    "    def surf_vec(self):\n",
    "        \"\"\" Plot velocity vectors as quivers. \"\"\"\n",
    "        time_sel = self.time_slider[1] # show map for last day on time slider\n",
    "        \n",
    "        return ds_ssh.where(ds_ssh.days==time_sel, drop=True).squeeze('time'\n",
    "                    ).hvplot.vectorfield(x='longitude', y='latitude', \n",
    "                                         angle='angle', mag='mag',\n",
    "                                         geo=True, hover=False).opts(magnitude='mag')\n",
    "    \n",
    "    @param.depends('surface_var', 'time_slider', 'alpha_slider')\n",
    "    def plot_surface(self):\n",
    "        \"\"\" Plot surface variable of choice. \"\"\"\n",
    "        time_sel = self.time_slider[1] # show map for last day on time slider\n",
    "        \n",
    "        ds_all = surface_var_map[self.surface_var]\n",
    "        ds = ds_all.where(ds_all.days==time_sel, drop=True).squeeze('time')\n",
    "        if self.surface_var == 'FSLE':    \n",
    "            surf_plot = ds.hvplot.image(geo=True)\n",
    "            surf_plot.opts(clim=(-0.6,0), cmap='Blues_r', clabel='FSLE')\n",
    "        elif self.surface_var == 'SSH':\n",
    "            surf_plot = ds.hvplot.image(geo=True)\n",
    "            surf_plot.opts(clim=(-1,0), cmap='cividis', clabel='SSH')\n",
    "        else: \n",
    "            surf_plot = ds.hvplot.image(geo=True)\n",
    "            surf_plot.opts(clim=(-0.3,0.3), cmap='RdBu_r', clabel='SSHA')\n",
    "        \n",
    "        surf_plot.opts(frame_width=450, alpha=self.alpha_slider, tools=['hover'], hooks=[self._set_tools])\n",
    "\n",
    "        return surf_plot\n",
    "        \n",
    "   \n",
    "    def view(self):\n",
    "        \"\"\" Make lat-lon plot with surface vars, bathymetry, and glider tracks. \"\"\"\n",
    "        return (hv.DynamicMap(self.plot_surface)\n",
    "                * hv.DynamicMap(self.surf_tiles)\n",
    "                * hv.DynamicMap(self.surf_vec)\n",
    "                * hv.DynamicMap(self.plot_traj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GliderVerticalSectionPlot(GliderParams):\n",
    "    \"\"\" Class containing the setup for the glider section plot \"\"\"\n",
    "    \n",
    "    @param.depends('density_range', 'density_gradation', 'glider_grid','glider_num')\n",
    "    def density_contours(self):\n",
    "        \"\"\" Plot the density contours. \"\"\"\n",
    "        #print('in contour')\n",
    "        contour = glider_map[self.glider_num][self.glider_grid]['potdens'].hvplot.contour(\n",
    "                        flip_yaxis=True, levels=np.linspace(self.density_range[0],\n",
    "                        self.density_range[1],self.density_gradation)\n",
    "                        ).opts(tools=[])\n",
    "        return contour\n",
    "    \n",
    "    @param.depends('anomaly_boolean', 'glider_grid', 'glider_num', 'glider_var')\n",
    "    def glider_image(self):\n",
    "        \"\"\" Plot the image for the glider section. \"\"\"\n",
    "        # Change the data set if wanting to plot anomaly\n",
    "        if self.anomaly_boolean:\n",
    "            glid_ds = glider_map_anom\n",
    "        else:\n",
    "            glid_ds = glider_map\n",
    "\n",
    "        # plot the image in Distance or Time\n",
    "        if self.glider_grid=='Distance grid':\n",
    "            image = hv.Image( \n",
    "                    (glid_ds[self.glider_num][self.glider_grid].distance, \n",
    "                     glid_ds[self.glider_num][self.glider_grid].pressure,\n",
    "                     glid_ds[self.glider_num][self.glider_grid][self.glider_var]), \n",
    "                    ['Distance [km]', 'Pressure [dBar]'], self.glider_var)\n",
    "\n",
    "        else:\n",
    "            image = hv.Image( \n",
    "                    (glid_ds[self.glider_num][self.glider_grid].time, \n",
    "                     glid_ds[self.glider_num][self.glider_grid].pressure,\n",
    "                     glid_ds[self.glider_num][self.glider_grid][self.glider_var]), \n",
    "                    ['Time [days]', 'Pressure [dBar]'], self.glider_var)\n",
    "        \n",
    "        # estimate the color range so that outliers don't create problems\n",
    "        bin_range = np.nanpercentile(glid_ds[self.glider_num][self.glider_grid][self.glider_var], [.5,99.5])\n",
    "        \n",
    "        # set properties for image like colorbar etcs.\n",
    "        image = image.opts(opts.Image(\n",
    "                        colorbar=True,\n",
    "                        cmap=self.var_colormap,\n",
    "                        invert_yaxis=True,\n",
    "                        clim=(bin_range[0], bin_range[1]),\n",
    "                        width=800,\n",
    "                        tools=['hover'], hooks=[self._set_tools]\n",
    "                        ))\n",
    "        return image\n",
    "\n",
    "    def viewable(self):\n",
    "        \"\"\" Make combined plot of the glider section. \"\"\"\n",
    "        image = hv.DynamicMap(self.glider_image).hist()\n",
    "                \n",
    "        title = (str(self.time_slider[0]) +'-'+ str(self.time_slider[1])\n",
    "                 + ' Days & ' + str(int(self.distance_slider[0]))+'-'\n",
    "                 + str(int(self.distance_slider[1])) + ' km')\n",
    "        \n",
    "        if self.glider_grid=='Distance grid':\n",
    "            image.opts(opts.Image(xlim = self.distance_slider, title=title))\n",
    "        else:\n",
    "            image.opts(opts.Image(xlim = self.time_slider, title=title))\n",
    "\n",
    "        # add the density contours or not. \n",
    "        if self.density_boolean:\n",
    "            return image*hv.DynamicMap(self.density_contours)\n",
    "        else:\n",
    "            return image\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GliderCombinedPlot(GliderTrajectoryPlot, GliderVerticalSectionPlot):\n",
    "    \"\"\" Acombined class that inherits the above classes and will be used to define the main object. \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard = GliderCombinedPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_title = '## Southern Ocean Glider Observations of the Submesoscales\\n Interactive dashboard to explore glider data collected in the Southern Ocean (zoom out on top panel to see exact location) during May-August 2019'\n",
    "text_tip = '*Tip: The box select tool (from tools on top right of this plot) can be used to select a range on the histogram plot to the right, which adjusts the color limits for the section plot*'\n",
    "dashboard_panel = pn.Column(pn.Row(\n",
    "                                pn.Param(dashboard.param, name=''),\n",
    "                                pn.Column(pn.panel(text_title),dashboard.view())), \n",
    "                            pn.Column(\n",
    "                                dashboard.viewable, \n",
    "                                pn.panel(text_tip))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to comment out and uncomment the different lines below based on how you want to view the dashboard. By default we have it setup to be able to view the dashboard directly as a standalone app using the Binder panel button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To render in this notebook and make available as a panel app\n",
    "dashboard_panel.servable()\n",
    "\n",
    "# To run locally in a standalone browser window (this may not work on Binder)\n",
    "#dashboard_panel.show()\n",
    "\n",
    "# To display in notebook cell below\n",
    "#dashboard_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ec_2021_gliderviz]",
   "language": "python",
   "name": "conda-env-ec_2021_gliderviz-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "248.182px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
